# Spark MLlib을 이용한 택시 요금 예측 회귀 분석 (심화 학습 가이드)

안녕하세요, 석이님! 이 문서는 `08_01_Regression.ipynb`와 `08_02_Regression.ipynb`의 내용을 바탕으로, Spark MLlib을 활용한 회귀 분석을 혼자서도 깊이 있게 학습하실 수 있도록 구성한 가이드입니다.

## 학습 목표
1.  **선형 회귀(Linear Regression)**의 기본 개념을 이해합니다.
2.  Spark MLlib을 사용하여 **단순 선형 회귀**와 **다중 선형 회귀** 모델을 구축하고 차이점을 이해합니다.
3.  머신러닝의 핵심 전처리 과정인 **특성 공학(Feature Engineering)**의 중요성을 파악합니다.
4.  여러 전처리 단계를 체계적으로 관리하는 **ML 파이프라인(Pipeline)**의 개념과 장점을 학습합니다.

---

## 1. 핵심 개념 미리보기

코드를 살펴보기 전, 핵심 개념들을 먼저 이해하면 학습에 큰 도움이 됩니다.

| 개념 | 설명 | 왜 중요할까? |
| :--- | :--- | :--- |
| **회귀 (Regression)** | 하나 이상의 변수(독립 변수)를 사용하여 다른 변수(종속 변수)의 값을 **예측**하는 통계 기법입니다. (예: `거리`로 `요금` 예측) | 미래의 수치 값을 예측하는 많은 문제(주가 예측, 수요 예측 등)를 해결할 수 있습니다. |
| **특성 (Feature)** | 모델이 예측을 위해 사용하는 입력 변수입니다. (예: `운행 거리`, `승객 수`) | 어떤 특성을 사용하느냐에 따라 모델의 성능이 크게 달라집니다. '쓰레기를 넣으면 쓰레기가 나온다'는 말처럼 중요한 과정입니다. |
| **레이블 (Label)** | 모델이 예측하고자 하는 목표 변수입니다. (예: `총 요금`) | 모델이 맞춰야 하는 '정답'에 해당합니다. |
| **VectorAssembler** | Spark MLlib의 변환기(Transformer)로, 여러 특성 컬럼을 하나의 **벡터(Vector)** 컬럼으로 합쳐줍니다. | Spark MLlib의 많은 모델은 입력 특성을 단일 벡터 형태로 받기 때문에 필수적인 단계입니다. |
| **ML 파이프라인** | 데이터 전처리, 특성 공학, 모델 훈련 등 머신러닝의 여러 단계를 하나의 작업 흐름으로 묶어주는 도구입니다. | 코드의 재사용성을 높이고, 훈련/테스트 데이터에 동일한 변환을 일관되게 적용하여 실수를 줄여줍니다. |

---

## 2. 단계별 학습: 단순 선형 회귀 (`08_01_Regression.ipynb`)

첫 번째 노트북에서는 가장 기본적인 회귀 모델을 만듭니다. **'운행 거리'라는 단 하나의 특성**으로 **'택시 요금'을 예측**하는 과정입니다.

### 과정 요약
1.  **데이터 준비**: 택시 운행 기록(`trips`)을 불러와 `trip_distance`와 `total_amount` 컬럼만 선택하고, 이상치를 제거합니다.
2.  **특성 벡터화**: `VectorAssembler`를 사용해 `trip_distance`를 `features`라는 벡터 컬럼으로 변환합니다.
3.  **모델 훈련**: `LinearRegression` 모델을 생성하고, 준비된 데이터로 훈련(`fit`)시킵니다.
4.  **성능 평가**: 훈련된 모델이 얼마나 정확한지 RMSE와 R² 지표로 확인합니다.

### 모델 성능 분석
-   **RMSE (평균 제곱근 오차)**: 약 `6.3`
    -   모델의 예측값이 실제값과 평균적으로 약 6.3달러 정도 차이 난다는 의미입니다.
-   **R² (결정 계수)**: 약 `0.76`
    -   모델이 택시 요금 변동의 약 76%를 '운행 거리'만으로 설명할 수 있다는 의미입니다.

> **🤔 생각해보기**: 운행 거리만으로 요금을 예측하는 것은 한계가 명확합니다. 같은 거리를 가더라도 **시간대(심야 할증), 요일(주말), 탑승 위치**에 따라 요금이 달라질 수 있습니다. 어떻게 하면 모델을 더 똑똑하게 만들 수 있을까요?

---

## 3. 심화 학습: 다중 선형 회귀와 파이프라인 (`08_02_Regression.ipynb`)

두 번째 노트북에서는 첫 번째 모델의 한계를 극복하기 위해 **더 많은 특성을 사용**하고, 복잡한 전처리 과정을 **파이프라인으로 자동화**합니다.

### 주요 개선점
1.  **다양한 특성 추가 (Feature Engineering)**
    -   기존 `trip_distance` 외에 `passenger_count`, `pickup_time`, `day_of_week`, `pickup_location_id` 등을 추가하여 모델에 더 많은 정보를 제공합니다.

2.  **고급 전처리 기법 도입**
    -   **범주형 데이터 처리**: 모델은 'Monday' 같은 문자열을 이해하지 못합니다.
        -   `StringIndexer`: 'Monday', 'Tuesday' 등을 숫자(0.0, 1.0...)로 변환합니다.
        -   `OneHotEncoder`: 변환된 숫자를 `[1,0,0,0]`, `[0,1,0,0]` 같은 벡터로 만들어, 숫자 크기에 따른 왜곡(e.g., 2.0이 1.0보다 중요하다고 착각하는 것)을 방지합니다.
    -   **수치형 데이터 스케일링**: `trip_distance`(0~500)와 `passenger_count`(1~4)처럼 값의 범위가 크게 다르면 모델 학습에 문제가 생길 수 있습니다.
        -   `StandardScaler`: 모든 수치형 데이터의 단위를 표준화하여(평균 0, 분산 1) 모델이 각 특성을 공평하게 학습하도록 돕습니다.

3.  **ML 파이프라인 구축**
    -   위에서 설명한 모든 전처리 단계(`StringIndexer`, `OneHotEncoder`, `StandardScaler`, `VectorAssembler`)와 모델(`LinearRegression`)을 `stages`로 정의하고 `Pipeline`으로 묶었습니다.
    -   **장점**:
        -   `pipeline.fit(train_df)` 한 줄만 실행하면 모든 전처리 및 훈련 과정이 자동으로 진행됩니다.
        -   `pipeline.transform(test_df)`를 통해 테스트 데이터에도 훈련 때와 **동일한 순서와 방법**으로 전처리가 적용되어 일관성이 유지됩니다.

### 모델 성능 비교

| 지표 | 단순 회귀 (08_01) | 다중 회귀 (08_02) | 해석 |
| :--- | :--- | :--- | :--- |
| **RMSE** | 6.3 | **5.6** | **오차가 줄었습니다.** 모델의 예측이 더 정확해졌습니다. |
| **R²** | 0.76 | **0.81** | **설명력이 높아졌습니다.** 모델이 요금 변동의 81%를 설명할 수 있게 되었습니다. |

**결론**: 다양한 특성을 추가하고 적절한 전처리를 거치자 모델의 성능이 크게 향상되었습니다. 이는 **좋은 특성을 발굴하고 가공하는 '특성 공학'이 머신러닝에서 얼마나 중요한지**를 보여주는 좋은 예시입니다.

## 최종 정리 및 다음 단계
-   **단순 회귀**는 하나의 특성으로 현상을 단순하게 설명하는 반면, **다중 회귀**는 여러 특성을 종합하여 더 정확한 예측을 가능하게 합니다.
-   Spark MLlib의 **파이프라인**은 복잡한 머신러닝 작업을 체계적이고 재사용 가능하게 만들어주는 강력한 도구입니다.
-   **더 나아가기**:
    -   `RandomForestRegressor`나 `GBTRegressor` 같은 다른 회귀 모델을 사용해보면 어떨까요?
    -   `tpep_pickup_datetime`과 `tpep_dropoff_datetime`의 차이를 계산하여 `trip_duration`(운행 시간)이라는 새로운 특성을 만들어보면 성능이 더 오를까요?
    -   `CrossValidator`와 `ParamGridBuilder`를 사용해 최적의 모델 파라미터를 찾아보는 **하이퍼파라미터 튜닝**에 도전해볼 수 있습니다.

이 가이드가 Spark를 이용한 머신러닝의 첫걸음에 든든한 디딤돌이 되기를 바랍니다.